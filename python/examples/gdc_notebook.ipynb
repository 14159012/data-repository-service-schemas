{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA4GH Data Access Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, metadata have been loaded into a test data registry so they can be accessed using GA4GH methods. `python gdc_dos.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the client and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will import a Python client and models for accessing data as defined in the schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ga4gh.dos.client import Client\n",
    "local_client = Client('http://localhost:8080/')\n",
    "client = local_client.client\n",
    "models = local_client.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Data Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list the existing Data Objects, we send a ListDataObjectsRequest to the `ListDataObjects` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Objects: 0 \n"
     ]
    }
   ],
   "source": [
    "ListDataObjectsRequest = models.get_model('ga4ghListDataObjectsRequest')\n",
    "list_request = client.ListDataObjects(body=ListDataObjectsRequest(page_size=10000000))\n",
    "list_response = list_request.result()\n",
    "print(\"Number of Data Objects: {} \".format(len(list_response.data_objects)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Data Object messages are for testing purposes only but should contain enough to retrieve their contents from GDC servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://api.gdc.cancer.gov/data/8ecfa039-cd6a-4c1a-822c-a1fca0763c3f, file_size (B): 519261\n"
     ]
    }
   ],
   "source": [
    "data_objects = list_response.data_objects\n",
    "data_object = data_objects[11]\n",
    "print('url: {}, file_size (B): {}'.format(data_object.urls[0].url, data_object.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Public Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use this service to eventually download data, but first we must find data we have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of public Data Objects: 3045\n"
     ]
    }
   ],
   "source": [
    "public_data_objects = filter(\n",
    "    lambda x: x['urls'][0]['system_metadata']['access'] == 'open', \n",
    "    data_objects)\n",
    "print('Number of public Data Objects: {}'.format(len(public_data_objects)))\n",
    "\n",
    "public_data_object = public_data_objects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then download this file and name it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# https://stackoverflow.com/questions/16694907/how-to-download-large-file-in-python-with-requests-py\n",
    "def download_file(url, filename):\n",
    "    # NOTE the stream=True parameter\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                #f.flush() commented by recommendation from J.F.Sebastian\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(public_data_object.urls[0].url, data_object.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the checksum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Object messages contain checksums of the underlying files. We can validate it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ga4ghChecksum(checksum=u'e88715863824b6a714a90d7ca340916a', type=u'md5')]\n"
     ]
    }
   ],
   "source": [
    "print(public_data_object.checksums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732d394e3b58fcf9ae5531b9f8d8ad43\n",
      "670b61d2b86b2090060eff38872a45e9\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "given_checksum = public_data_object.checksums[0].checksum\n",
    "\n",
    "# https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file\n",
    "import hashlib\n",
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "print(md5(data_object.name))\n",
    "print(given_checksum)\n",
    "print(given_checksum == md5(data_object.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the contents of the registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we look at the file sizes of the contents of the registry. This is a histogram where each bin is a count of the number of files with a size in that range. We plot with a log axis because of the number of very small files dominates a linear scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_objects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-817869c4dadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfile_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_objects\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n = {}, {} GB total, mean {} GB\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_sizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000000000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_sizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000000000.0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'symlog'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_objects' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "file_sizes = [float(x.file_size) for x in data_objects]\n",
    "plt.hist(file_sizes, bins=96)\n",
    "plt.title(\"n = {}, {} GB total, mean {} GB\".format(len(file_sizes), str(sum(file_sizes) / 1000000000.0), (sum(file_sizes) / len(file_sizes)) / 1000000000.0 ))\n",
    "plt.yscale('symlog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that most of the non-tiny files are around 2GB and a few files are very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make a Data Bundle of some Data Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now organize some of the Data Objects into a bundle so we can share them together. \n",
    "\n",
    "For example, a few publicly available items. First, we have to gather the list of data objects and compute their concatenated hash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the hash for our Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93e75792-4e71-43be-91d1-c69c461b567f\n",
      "670b61d2b86b2090060eff38872a45e9\n",
      "d64983aa044c72e05b8e0e61e3f1b64c\n"
     ]
    }
   ],
   "source": [
    "public_data_object_ids = [x.id for x in public_data_objects]\n",
    "print(public_data_object_ids[0])\n",
    "hashes = [x.checksums[0].checksum for x in public_data_objects]\n",
    "print(hashes[0])\n",
    "bundle_md5 = hashlib.md5()\n",
    "bundle_md5.update(''.join(hashes[0:10]))\n",
    "bundle_digest = bundle_md5.hexdigest()\n",
    "print(bundle_digest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Data Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121dc9f-c8a4-436a-b4c4-c3c7fa58b5dc\n"
     ]
    }
   ],
   "source": [
    "CreateDataBundleRequest = models.get_model('ga4ghCreateDataBundleRequest')\n",
    "DataBundle = models.get_model('ga4ghDataBundle')\n",
    "Checksum = models.get_model('ga4ghChecksum')\n",
    "my_bundle = DataBundle(\n",
    "    name=\"My Bundle\",\n",
    "    checksums=[Checksum(checksum=bundle_digest, type='md5')],\n",
    "    data_object_ids=public_data_object_ids[0:10],\n",
    "    aliases=[\"bundle-alias\", \"access:public\"])\n",
    "create_request = CreateDataBundleRequest(data_bundle=my_bundle)\n",
    "create_response = client.CreateDataBundle(body=create_request).result()\n",
    "print(create_response.data_bundle_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify the Data Bundle appears as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'93e75792-4e71-43be-91d1-c69c461b567f', u'0723954e-37b4-4a04-bd58-c685962b8a78', u'cfc60287-61ff-4631-a318-b0ad49a06c11', u'7d8c060a-f616-4a7c-963a-5aa237b040a0', u'6c57b1e9-a5b2-49ac-96a8-c5d090dd9cb1', u'6e5774ac-10aa-40b9-b901-b0776c3a1b33', u'76abc4c9-7977-447e-9bc3-8b06a1417682', u'07758321-c528-4760-aec0-269470c5be35', u'33942f1a-cf23-4545-8110-f767c623c721', u'8176bc53-925e-47ff-8eb7-ccd1e5612d60']\n"
     ]
    }
   ],
   "source": [
    "get_bundle_response = client.GetDataBundle(data_bundle_id=create_response.data_bundle_id).result()\n",
    "print(get_bundle_response.data_bundle.data_object_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
